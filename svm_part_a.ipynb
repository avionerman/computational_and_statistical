{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vCCbNrCwUeRZ",
        "fJPdbjA6UbnG",
        "CBgA6GitUYsY",
        "uL8UcmG5UU_v",
        "3vj0zNSOdaFf",
        "2e8KJgALVXyL",
        "C4mBbJnHVcSP",
        "eNUwssXb7VjD"
      ],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOEkke0vCadRelyzJW7KLPj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avionerman/computational_and_statistical/blob/main/svm_part_a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports, Data Loading & Data subsets"
      ],
      "metadata": {
        "id": "LmzmF6wEwdCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# from tensorflow.keras.datasets import cifar10\n",
        "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "!pip install cupy-cuda12x\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "B9CA5AUDATiv",
        "outputId": "f69863a7-04c1-4adb-cde3-27eb2ffc01d5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.12/dist-packages (13.6.0)\n",
            "Requirement already satisfied: numpy<2.6,>=1.22 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x) (2.0.2)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x) (0.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzPRxdTS4DcH",
        "outputId": "9e3203f7-2f38-4ebb-83d3-2439668cbbd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "start_bold = \"\\u001b[1m\"\n",
        "end_bold = \"\\033[0m\"\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "# x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
        "\n",
        "class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "# # 10% train subset\n",
        "x_train, _, y_train, _ = train_test_split(x_train, y_train, test_size=0.95, stratify=y_train, random_state=42)\n",
        "\n",
        "# # 10% test subset\n",
        "# x_test, _, y_test, _ = train_test_split(x_test, y_test, test_size=0.90, stratify=y_test, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing phase"
      ],
      "metadata": {
        "id": "7AEiVWX4UkgS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flatten enablement"
      ],
      "metadata": {
        "id": "vCCbNrCwUeRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Flatten step #####\n",
        "\n",
        "print(start_bold + \"Flattening explanation:\" + end_bold)\n",
        "print(\"Flattening the data, is highly needed since both PCA and SVM cannot accept 3D data. \\n\"\n",
        "\"PCA calculates the covariance matrix among features. \\n\"\n",
        "\"That said, it needs an array of [samples x features], where each faeture is a column.\\n\")\n",
        "\n",
        "x_train = x_train.reshape(len(x_train), -1)\n",
        "x_test  = x_test.reshape(len(x_test), -1)\n",
        "# x_train.shape, x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ULkKyRB8ubh",
        "outputId": "bc5ab0b8-e87b-4f64-8367-e92ab0c67f98"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mFlattening explanation:\u001b[0m\n",
            "Flattening the data, is highly needed since both PCA and SVM cannot accept 3D data. \n",
            "PCA calculates the covariance matrix among features. \n",
            "That said, it needs an array of [samples x features], where each faeture is a column.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalization enablement"
      ],
      "metadata": {
        "id": "fJPdbjA6UbnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Normalization step #####\n",
        "\n",
        "print(start_bold + \"Normalization explanation:\" + end_bold)\n",
        "print(\"I want to normalize my data mainly because I want to: \\n\"\n",
        "\"[1] to prevent my upcoming models from being dominated by large features.\\n\"\n",
        "\"[2] to feed a better scale for calculating distances for my models.\\n\"\n",
        "\"[3] and to help my PCA step with meaningful directions instead of large ones.\\n\")\n",
        "\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test  = x_test.astype(\"float32\") / 255.0\n",
        "# print(x_train.min(), x_train.max(), x_test.min(), x_test.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ca1d256-e77d-4bcd-e450-85f50a7866a5",
        "id": "huwuvHUk-cmj"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mNormalization explanation:\u001b[0m\n",
            "I want to normalize my data mainly because I want to: \n",
            "[1] to prevent my upcoming models from being dominated by large features.\n",
            "[2] to feed a better scale for calculating distances for my models.\n",
            "[3] and to help my PCA step with meaningful directions instead of large ones.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standarization enablement"
      ],
      "metadata": {
        "id": "CBgA6GitUYsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Standarization step #####\n",
        "\n",
        "print(start_bold + \"Standarization explanation:\" + end_bold)\n",
        "print(\"I want to standarize my data mainly because I want to: \\n\"\n",
        "\"[1] make my PCA work better since features with high deviation will not dominate.\\n\"\n",
        "\"[2] help my SVM to use all the features in a common scale.\\n\"\n",
        "\"*will use fit only for the training set, to prevent data leakage.\\n\"\n",
        "\"**fit learns info from the data, while transform applies the learned info to new data .\\n\"\n",
        "\"***mean should be 0, and std. dev should be 1.\\n\")\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "print(\"The train mean (μ) is:\", x_train_scaled.mean(),\n",
        "      \"and the std. dev (σ) is:\", x_train_scaled.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ec6554-b816-4b9e-97ec-936fb5ba3998",
        "id": "_b0PewSzAdam"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mStandarization explanation:\u001b[0m\n",
            "I want to standarize my data mainly because I want to: \n",
            "[1] make my PCA work better since features with high deviation will not dominate.\n",
            "[2] help my SVM to use all the features in a common scale.\n",
            "*will use fit only for the training set, to prevent data leakage.\n",
            "**fit learns info from the data, while transform applies the learned info to new data .\n",
            "***mean should be 0, and std. dev should be 1.\n",
            "\n",
            "The train mean (μ) is: -2.2331874e-09 and the std. dev (σ) is: 1.0000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA enablement"
      ],
      "metadata": {
        "id": "uL8UcmG5UU_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### PCA (Principal component analysis) step #####\n",
        "\n",
        "print(start_bold + \"PCA explanation:\" + end_bold)\n",
        "print(\"To be updated: \\n\"\n",
        "\"*full: accurate, slow, memory heavy. \\n\"\n",
        "\"**auto: data shape (n_samples, n_features) -- recommended. \\n\")\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "pca = PCA(n_components=0.90, svd_solver=\"auto\", random_state=42)\n",
        "x_train_pca = pca.fit_transform(x_train_scaled)\n",
        "x_test_pca = pca.transform(x_test_scaled)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\">>> The total PCA time was: {(end_time - start_time):.2f} seconds ({(end_time - start_time)/60:.2f} minutes)\")\n",
        "print(\">>>\",[float((pca.explained_variance_ratio_.sum())), (x_train_scaled.shape[1]), (x_train_pca.shape[1])] )\n",
        "\n",
        "print(\"\\n\" + start_bold + \"PCA results:\" + end_bold)\n",
        "print(\"Apparently, only 103 components are needed to explain almost 90% of the variance.\\n\"\n",
        "\"That looks good, because we has a huge dimensionality reduction from 3072 to 103, and at the same time\"\n",
        "\"we didn't loose more than 10% of the total components.\")\n",
        "\n",
        "y_train_flat = y_train.ravel()\n",
        "y_test_flat  = y_test.ravel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f9d2f1a-42b0-4b19-ab80-d678a65489bf",
        "id": "qFNjQ7_5DRXE"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mPCA explanation:\u001b[0m\n",
            "To be updated: \n",
            "*full: accurate, slow, memory heavy. \n",
            "**auto: data shape (n_samples, n_features) -- recommended. \n",
            "\n",
            ">>> The total PCA time was: 21.10 seconds (0.35 minutes)\n",
            ">>> [0.9005500674247742, 3072, 94]\n",
            "\n",
            "\u001b[1mPCA results:\u001b[0m\n",
            "Apparently, only 103 components are needed to explain almost 90% of the variance.\n",
            "That looks good, because we has a huge dimensionality reduction from 3072 to 103, and at the same timewe didn't loose more than 10% of the total components.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test phase\n",
        "\n",
        "The scope of this phase is only about checking if the pipeline works, if I get a logical accuracy and if the PCA works as expected on the dataset.\n",
        "\n",
        "The optimization actions will come once the current step produces a logical baseline so we can start building on top of it in the following phase."
      ],
      "metadata": {
        "id": "x6sEijZmVIvn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train an SVM with LinearSVC (once)"
      ],
      "metadata": {
        "id": "3vj0zNSOdaFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(1)\n",
        "# from sklearn.svm import LinearSVC\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# import time\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# param_grid = {\n",
        "#     \"C\": [1]\n",
        "# }\n",
        "\n",
        "# grid = GridSearchCV(\n",
        "#     LinearSVC(max_iter=5000),\n",
        "#     param_grid=param_grid,\n",
        "#     n_jobs=1,\n",
        "#     verbose=3\n",
        "# )\n",
        "\n",
        "# start_time = time.time()\n",
        "# grid.fit(x_train_pca, y_train_flat)\n",
        "# train_time = time.time() - start_time\n",
        "\n",
        "# print(f\">>> The total LinearSVC time was: {train_time:.2f} seconds\")\n",
        "\n",
        "# y_train_pred_linearsvc = grid.predict(x_train_pca)\n",
        "# y_test_pred_linearsvc  = grid.predict(x_test_pca)\n",
        "\n",
        "# train_acc_w_linearsvc = accuracy_score(y_train_flat, y_train_pred_linearsvc)\n",
        "# test_acc_w_linearsvc  = accuracy_score(y_test_flat, y_test_pred_linearsvc)\n",
        "\n",
        "# print(f\">>> The train accuracy was {train_acc_w_linearsvc:.4f} and the test accuracy was {test_acc_w_linearsvc:.4f}\")\n",
        "\n",
        "# print(\"\\n\" + start_bold + \"LinearSVC results:\" + end_bold)\n",
        "# print(\"The train accuracy was close to 40%, same as the test accuracy.\\n\"\n",
        "# \"That looks good, firstly because we don't have to worry about overfitting, and secondly the pipeline is working as expected.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57slam6_deKg",
        "outputId": "ca42f5a4-c49e-42fc-9e79-22c293f49957"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train an SVM with SVC(kernel=linear) (once)"
      ],
      "metadata": {
        "id": "2e8KJgALVXyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(1)\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# import time\n",
        "\n",
        "# model = SVC(kernel=\"linear\", C=1.0, verbose=True)\n",
        "\n",
        "# start_time = time.time()\n",
        "# model.fit(x_train_pca, y_train_flat)\n",
        "# train_time = time.time() - start_time\n",
        "\n",
        "# print(f\">>> The total SVC (linear) time was: {train_time:.2f} seconds\")\n",
        "\n",
        "# y_train_pred = model.predict(x_train_pca)\n",
        "# y_test_pred  = model.predict(x_test_pca)\n",
        "\n",
        "# train_acc = accuracy_score(y_train_flat, y_train_pred)\n",
        "# test_acc  = accuracy_score(y_test_flat, y_test_pred)\n",
        "\n",
        "# print(f\">>> The train accuracy was {train_acc:.2f} and the test accuracy was {test_acc:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PfBkM49VhT9",
        "outputId": "0c756252-1be0-4044-f186-571dd56473d2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Selection - LinearSVC"
      ],
      "metadata": {
        "id": "C4mBbJnHVcSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import cupy as cp\n",
        "\n",
        "from cuml.svm import LinearSVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# transform data to GPU\n",
        "x_train_gpu = cp.asarray(x_train_pca)\n",
        "x_test_gpu  = cp.asarray(x_test_pca)\n",
        "y_train_gpu = cp.asarray(y_train_flat)\n",
        "\n",
        "param_grid = {\n",
        "    \"C\": [0.1, 1, 10]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=LinearSVC(max_iter=5000, tol=1e-3),\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "grid.fit(x_train_gpu, y_train_flat)\n",
        "grid_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\n >>> LinearSVC(GPU) total time: {grid_time:.2f} seconds\")\n",
        "\n",
        "best_model = grid.best_estimator_\n",
        "best_params = grid.best_params_\n",
        "\n",
        "print(\"\\n >>> LinearSVC(GPU) Summary\")\n",
        "print(\"--------------------------\")\n",
        "print(\"Best mean CV accuracy:\", grid.best_score_)\n",
        "print(\"Best params:\", best_params)\n",
        "\n",
        "# make the predictions on GPU\n",
        "y_train_pred = cp.asnumpy(best_model.predict(x_train_gpu))\n",
        "y_test_pred  = cp.asnumpy(best_model.predict(x_test_gpu))\n",
        "\n",
        "train_acc = accuracy_score(y_train_flat, y_train_pred)\n",
        "test_acc  = accuracy_score(y_test_flat,  y_test_pred)\n",
        "\n",
        "print(\"\\nFinal Evaluation:\")\n",
        "print(\"Train acc:\", train_acc)\n",
        "print(\"Test acc:\", test_acc)\n",
        "\n",
        "results = pd.DataFrame(grid.cv_results_)\n",
        "cv_table = results[[\"param_C\", \"mean_test_score\", \"std_test_score\", \"rank_test_score\"]]\n",
        "\n",
        "print(\"\\n >>> Cross-Validation outcome table\")\n",
        "print(cv_table.sort_values(\"rank_test_score\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2b123kPzi78",
        "outputId": "e1ab353d-b684-4872-ec7c-ddc3004c4fbe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
            "\n",
            " >>> LinearSVC(GPU) total time: 16.66 seconds\n",
            "\n",
            " >>> LinearSVC(GPU) Summary\n",
            "--------------------------\n",
            "Best mean CV accuracy: 0.34040000000000004\n",
            "Best params: {'C': 0.1}\n",
            "\n",
            "Final Evaluation:\n",
            "Train acc: 0.4612\n",
            "Test acc: 0.3461\n",
            "\n",
            " >>> Cross-Validation outcome table\n",
            "   param_C  mean_test_score  std_test_score  rank_test_score\n",
            "0      0.1           0.3404        0.021593                1\n",
            "2     10.0           0.3404        0.022571                1\n",
            "1      1.0           0.3400        0.022733                3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Selection - SVC(kernel=rbf)"
      ],
      "metadata": {
        "id": "eNUwssXb7VjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import cupy as cp\n",
        "\n",
        "from cuml.svm import SVC\n",
        "from cuml.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# transform data to GPU\n",
        "x_train_gpu = cp.asarray(x_train_pca)\n",
        "x_test_gpu  = cp.asarray(x_test_pca)\n",
        "y_train_gpu = cp.asarray(y_train_flat)\n",
        "\n",
        "param_grid_rbf = {\n",
        "    \"C\": [1, 10],\n",
        "    \"gamma\": [\"scale\"]\n",
        "}\n",
        "\n",
        "rbf_grid = GridSearchCV(\n",
        "    estimator=SVC(kernel=\"rbf\"),\n",
        "    param_grid=param_grid_rbf,\n",
        "    cv=5,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "rbf_grid.fit(x_train_gpu, y_train_flat)\n",
        "rbf_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\n >>> SVM(rbf, GPU) with GridSearchCV total execution time: {rbf_time:.2f} seconds\")\n",
        "\n",
        "best_rbf_score  = float(rbf_grid.best_score_)\n",
        "best_rbf_params = rbf_grid.best_params_\n",
        "best_rbf_model  = rbf_grid.best_estimator_\n",
        "\n",
        "print(\"\\n >>> SVM(rbf, GPU) Execution Summary\")\n",
        "print(\"----------------------------\")\n",
        "print(f\"Best mean CV accuracy: {best_rbf_score:.4f}\")\n",
        "print(f\"Best hyperparameters: {best_rbf_params}\")\n",
        "print(f\"Best model: {best_rbf_model}\")\n",
        "\n",
        "# --- make the predictions on GPU, and transform back to CPU for metrics (acc)\n",
        "y_train_pred_gpu = best_rbf_model.predict(x_train_gpu)\n",
        "y_test_pred_gpu  = best_rbf_model.predict(x_test_gpu)\n",
        "\n",
        "y_train_pred_rbf = cp.asnumpy(y_train_pred_gpu)\n",
        "y_test_pred_rbf  = cp.asnumpy(y_test_pred_gpu)\n",
        "\n",
        "train_acc_rbf = accuracy_score(y_train_flat, y_train_pred_rbf)\n",
        "test_acc_rbf  = accuracy_score(y_test_flat,  y_test_pred_rbf)\n",
        "\n",
        "print(\"\\n >>> Final Evaluation of the best SVM(rbf, GPU)\")\n",
        "print(f\"Train accuracy: {train_acc_rbf:.4f}\")\n",
        "print(f\"Test accuracy:  {test_acc_rbf:.4f}\")\n",
        "\n",
        "rbf_results = pd.DataFrame(rbf_grid.cv_results_)\n",
        "\n",
        "rbf_cv_table = rbf_results[\n",
        "    [\"param_C\", \"param_gamma\", \"mean_test_score\", \"std_test_score\", \"rank_test_score\"]\n",
        "]\n",
        "print(\"\\n >>> RBF Cross-Validation outcome table\")\n",
        "print(rbf_cv_table.sort_values(\"rank_test_score\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5c6b17b-f5df-42ff-cf93-801774895960",
        "id": "wRRB7qJg7VjE"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
            "\n",
            " >>> SVM(rbf, GPU) with GridSearchCV total execution time: 12.25 seconds\n",
            "\n",
            " >>> SVM(rbf, GPU) Execution Summary\n",
            "----------------------------\n",
            "Best mean CV accuracy: 0.4132\n",
            "Best hyperparameters: {'C': 1, 'gamma': 'scale'}\n",
            "Best model: SVC()\n",
            "\n",
            " >>> Final Evaluation of the best SVM(rbf, GPU)\n",
            "Train accuracy: 0.6984\n",
            "Test accuracy:  0.4076\n",
            "\n",
            " >>> RBF Cross-Validation outcome table\n",
            "   param_C param_gamma  mean_test_score  std_test_score  rank_test_score\n",
            "0        1       scale           0.4132        0.019904                1\n",
            "1       10       scale           0.4104        0.017727                2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Selection - SVC(kernel=linear)"
      ],
      "metadata": {
        "id": "ZeeO0nQA1u7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import cupy as cp\n",
        "\n",
        "from cuml.svm import SVC\n",
        "from cuml.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# transform to GPU\n",
        "x_train_gpu = cp.asarray(x_train_pca)\n",
        "x_test_gpu  = cp.asarray(x_test_pca)\n",
        "\n",
        "param_grid_linear = {\n",
        "    \"C\": [0.1, 1, 10]\n",
        "}\n",
        "\n",
        "linear_grid = GridSearchCV(\n",
        "    estimator=SVC(kernel=\"linear\"),\n",
        "    param_grid=param_grid_linear,\n",
        "    cv=5,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "linear_grid.fit(x_train_gpu, y_train_flat)\n",
        "linear_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\n >>> SVM(linear, GPU) with GridSearchCV total execution time: {linear_time:.2f} seconds\")\n",
        "\n",
        "best_linear_score  = float(linear_grid.best_score_)\n",
        "best_linear_params = linear_grid.best_params_\n",
        "best_linear_model  = linear_grid.best_estimator_\n",
        "\n",
        "print(\"\\n >>> SVM(linear, GPU) Execution Summary\")\n",
        "print(\"----------------------------\")\n",
        "print(f\"Best mean CV accuracy: {best_linear_score:.4f}\")\n",
        "print(f\"Best hyperparameters: {best_linear_params}\")\n",
        "print(f\"Best model: {best_linear_model}\")\n",
        "\n",
        "# make predictions on GPU, and transform results back to CPU\n",
        "y_train_pred_gpu = best_linear_model.predict(x_train_gpu)\n",
        "y_test_pred_gpu  = best_linear_model.predict(x_test_gpu)\n",
        "\n",
        "y_train_pred_linear = cp.asnumpy(y_train_pred_gpu)\n",
        "y_test_pred_linear  = cp.asnumpy(y_test_pred_gpu)\n",
        "\n",
        "train_acc_linear = accuracy_score(y_train_flat, y_train_pred_linear)\n",
        "test_acc_linear  = accuracy_score(y_test_flat,  y_test_pred_linear)\n",
        "\n",
        "print(\"\\n >>> Final Evaluation of the best SVM(linear, GPU)\")\n",
        "print(f\"Train accuracy: {train_acc_linear:.4f}\")\n",
        "print(f\"Test accuracy:  {test_acc_linear:.4f}\")\n",
        "\n",
        "linear_results = pd.DataFrame(linear_grid.cv_results_)\n",
        "\n",
        "linear_cv_table = linear_results[\n",
        "    [\"param_C\", \"mean_test_score\", \"std_test_score\", \"rank_test_score\"]\n",
        "]\n",
        "print(\"\\n >>> Linear Cross-Validation outcome table\")\n",
        "print(linear_cv_table.sort_values(\"rank_test_score\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FQ-6ilb19ab",
        "outputId": "2b659962-a52c-4fa3-f8ea-2c7b55b2402f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-12-07 17:47:00.279] [CUML] [warning] SVC with the linear kernel can be much faster using the specialized solver provided by LinearSVC. Consider switching to LinearSVC if tranining takes too long.\n",
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Selection - SVC(kernel=poly)\n",
        "\n"
      ],
      "metadata": {
        "id": "1c3sWyz934A8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_poly = {\n",
        "    \"C\": [1, 10],\n",
        "    \"degree\": [2, 3]\n",
        "}\n",
        "\n",
        "grid_poly = GridSearchCV(\n",
        "    estimator=SVC(kernel=\"poly\", gamma=\"scale\", coef0=0),\n",
        "    param_grid=param_grid_poly,\n",
        "    cv=5,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "start = time.time()\n",
        "grid_poly.fit(x_train_pca, y_train_flat)\n",
        "time_poly = time.time() - start\n",
        "\n",
        "print(f\"\\n>>> SVC(poly) GridSearchCV time: {time_poly:.2f} sec\")\n",
        "print(\"Best params:\", grid_poly.best_params_)\n",
        "print(\"Best CV score:\", grid_poly.best_score_)\n",
        "\n",
        "best_poly = grid_poly.best_estimator_\n",
        "\n",
        "y_train_pred_poly = best_poly.predict(x_train_pca)\n",
        "y_test_pred_poly  = best_poly.predict(x_test_pca)\n",
        "\n",
        "train_acc_poly = accuracy_score(y_train_flat, y_train_pred_poly)\n",
        "test_acc_poly  = accuracy_score(y_test_flat,  y_test_pred_poly)\n",
        "\n",
        "print(\"\\n>>> Final SVC (poly)\")\n",
        "print(f\"Train accuracy: {train_acc_poly:.4f}\")\n",
        "print(f\"Test accuracy:  {test_acc_poly:.4f}\")\n"
      ],
      "metadata": {
        "id": "GpVmoTy-3_46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# kNN & NCC models"
      ],
      "metadata": {
        "id": "3e8-RMY3vqWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "\n",
        "from cuml.neighbors import KNeighborsClassifier as cuKNN  # GPU KNN\n",
        "from sklearn.neighbors import NearestCentroid             # CPU NCC\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from scipy import sparse\n",
        "\n",
        "# transform data for GPU\n",
        "if sparse.issparse(x_train_pca):\n",
        "    x_train_dense = x_train_pca.toarray()\n",
        "    x_test_dense  = x_test_pca.toarray()\n",
        "else:\n",
        "    x_train_dense = x_train_pca\n",
        "    x_test_dense  = x_test_pca\n",
        "\n",
        "x_train_gpu = cp.asarray(x_train_dense)\n",
        "x_test_gpu  = cp.asarray(x_test_dense)\n",
        "y_train_gpu = cp.asarray(y_train_flat)\n",
        "\n",
        "k_values = list(range(1, 15))\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "best_k = None\n",
        "best_cv_score = -1.0\n",
        "k_scores = []\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "print(\"\\n>>> Starting KNN (GPU) cross-validation over k...\\n\")\n",
        "for k in k_values:\n",
        "    fold_scores = []\n",
        "\n",
        "    for train_idx, val_idx in cv.split(x_train_pca, y_train_flat):\n",
        "\n",
        "\n",
        "        x_tr_gpu = x_train_gpu[train_idx]\n",
        "        y_tr_gpu = y_train_gpu[train_idx]\n",
        "        x_val_gpu = x_train_gpu[val_idx]\n",
        "        y_val = y_train_flat[val_idx]\n",
        "\n",
        "        knn_gpu = cuKNN(n_neighbors=k)\n",
        "        knn_gpu.fit(x_tr_gpu, y_tr_gpu)\n",
        "\n",
        "        # predict with GPU and then transform to CPU\n",
        "        y_val_pred_gpu = knn_gpu.predict(x_val_gpu)\n",
        "        y_val_pred = cp.asnumpy(y_val_pred_gpu)\n",
        "\n",
        "        fold_scores.append(accuracy_score(y_val, y_val_pred))\n",
        "\n",
        "    mean_score = float(np.mean(fold_scores))\n",
        "    k_scores.append((k, mean_score))\n",
        "    print(f\"k={k:3d} | mean CV accuracy={mean_score:.4f}\")\n",
        "\n",
        "    if mean_score > best_cv_score:\n",
        "        best_cv_score = mean_score\n",
        "        best_k = k\n",
        "\n",
        "knn_cv_time = time.time() - start\n",
        "\n",
        "print(f\"\\n>>> Best k from CV: {best_k} with mean accuracy {best_cv_score:.4f}\")\n",
        "print(f\">>> KNN CV search time (GPU): {knn_cv_time:.2f} sec\\n\")\n",
        "\n",
        "# train the final kNN using the best k on full training set (with GPU)\n",
        "best_knn_gpu = cuKNN(n_neighbors=best_k)\n",
        "\n",
        "start = time.time()\n",
        "best_knn_gpu.fit(x_train_gpu, y_train_gpu)\n",
        "knn_train_time = time.time() - start\n",
        "\n",
        "start = time.time()\n",
        "y_test_pred_gpu = best_knn_gpu.predict(X_test_gpu)\n",
        "knn_test_time = time.time() - start\n",
        "\n",
        "# bring the predictions for accuracy and transform back to CPU\n",
        "y_test_pred = cp.asnumpy(y_test_pred_gpu)\n",
        "y_train_pred = cp.asnumpy(best_knn_gpu.predict(x_train_gpu))\n",
        "\n",
        "knn_train_acc = accuracy_score(y_train_flat, y_train_pred)\n",
        "knn_test_acc  = accuracy_score(y_test_flat,  y_test_pred)\n",
        "\n",
        "print(\"\\n KNN (k-Nearest Neighbors, GPU)\\n\")\n",
        "print(f\"Best k from CV: \", best_k)\n",
        "print(f\"CV search time (GPU): {knn_cv_time:.2f} sec\")\n",
        "print(f\"Train time (best k only): {knn_train_time:.2f} sec\")\n",
        "print(f\"Test time: {knn_test_time:.2f} sec\\n\")\n",
        "print(f\"Train accuracy (best k): {knn_train_acc:.4f}\")\n",
        "print(f\"Test accuracy  (best k): {knn_test_acc:.4f}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "ncc = NearestCentroid()\n",
        "\n",
        "start = time.time()\n",
        "ncc.fit(x_train_pca, y_train_flat)\n",
        "ncc_train_time = time.time() - start\n",
        "\n",
        "start = time.time()\n",
        "y_test_pred_ncc = ncc.predict(x_test_pca)\n",
        "ncc_test_time = time.time() - start\n",
        "\n",
        "ncc_train_acc = ncc.score(x_train_pca, y_train_flat)\n",
        "ncc_test_acc  = ncc.score(x_test_pca,  y_test_flat)\n",
        "\n",
        "print(\"\\n NCC (Nearest Class Centroid)\\n\")\n",
        "print(f\"Train time: {ncc_train_time:.4f} sec\")\n",
        "print(f\"Test time: {ncc_test_time:.4f} sec\\n\")\n",
        "print(f\"Train accuracy: {ncc_train_acc:.4f}\")\n",
        "print(f\"Test accuracy: {ncc_test_acc:.4f}\\n\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oeuc-ziKvubI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary results"
      ],
      "metadata": {
        "id": "ZELITlzV3Hc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "summary = pd.DataFrame([\n",
        "    [\"LinearSVC\",  train_acc, test_acc, grid_time],\n",
        "    [\"RBF SVM\",    train_acc_rbf,    test_acc_rbf,    rbf_time],\n",
        "    [\"Linear SVM\", train_acc_linear, test_acc_linear, linear_time],\n",
        "    [\"Poly SVM\",   train_acc_poly,   test_acc_poly,   time_poly],\n",
        "    [\"kNN\",  knn_train_acc,    knn_test_acc,    knn_train_time],\n",
        "    [\"NCC\",        ncc_train_acc,    ncc_test_acc,    ncc_train_time],\n",
        "], columns=[\"Model\", \"Train Accuracy\", \"Test Accuracy\", \"Train Time (s)\"])\n",
        "\n",
        "print(\"\\n Summary results\")\n",
        "print(summary)\n"
      ],
      "metadata": {
        "id": "4Mnyd4O63JHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cateforization examples (visualization)"
      ],
      "metadata": {
        "id": "bvGyYVaCsG5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_examples(images, y_true, y_pred, class_names, correct=True, n=6, title=\"\"):\n",
        "    \"\"\"\n",
        "    images: original x_test (not PCA)\n",
        "    y_true: real labels\n",
        "    y_pred: predicted labels\n",
        "    correct=True -> show correct predictions\n",
        "    correct=False -> show incorrect predictions\n",
        "    \"\"\"\n",
        "\n",
        "    if correct:\n",
        "        idx = np.where(y_true == y_pred)[0]\n",
        "    else:\n",
        "        idx = np.where(y_true != y_pred)[0]\n",
        "\n",
        "    if len(idx) == 0:\n",
        "        print(\"No examples found for this case.\")\n",
        "        return\n",
        "\n",
        "    chosen = np.random.choice(idx, size=min(n, len(idx)), replace=False)\n",
        "\n",
        "    plt.figure(figsize=(15, 4))\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "\n",
        "    for i, j in enumerate(chosen):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.imshow(images[j].reshape(32, 32, 3))\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(f\"T: {class_names[y_true[j]]}\\nP: {class_names[y_pred[j]]}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "show_examples(\n",
        "    x_test,\n",
        "    y_test_flat,\n",
        "    y_test_pred,\n",
        "    class_names,\n",
        "    correct=True,\n",
        "    n=6,\n",
        "    title=\"LinearSVC – Correct Predictions\"\n",
        ")\n",
        "\n",
        "show_examples(\n",
        "    x_test,\n",
        "    y_test_flat,\n",
        "    y_test_pred,\n",
        "    class_names,\n",
        "    correct=False,\n",
        "    n=6,\n",
        "    title=\"LinearSVC – Incorrect Predictions\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "show_examples(\n",
        "    x_test,\n",
        "    y_test_flat,\n",
        "    y_test_pred_rbf,\n",
        "    class_names,\n",
        "    correct=True,\n",
        "    n=6,\n",
        "    title=\"RBF SVM – Correct Predictions\"\n",
        ")\n",
        "\n",
        "show_examples(\n",
        "    x_test,\n",
        "    y_test_flat,\n",
        "    y_test_pred_rbf,\n",
        "    class_names,\n",
        "    correct=False,\n",
        "    n=6,\n",
        "    title=\"RBF SVM – Incorrect Predictions\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "show_examples(\n",
        "    x_test,\n",
        "    y_test_flat,\n",
        "    y_test_pred_linear,\n",
        "    class_names,\n",
        "    correct=True,\n",
        "    n=6,\n",
        "    title=\"Linear SVM – Correct Predictions\"\n",
        ")\n",
        "\n",
        "show_examples(\n",
        "    x_test,\n",
        "    y_test_flat,\n",
        "    y_test_pred_linear,\n",
        "    class_names,\n",
        "    correct=False,\n",
        "    n=6,\n",
        "    title=\"Linear SVM – Incorrect Predictions\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "show_examples(\n",
        "    x_test,\n",
        "    y_test_flat,\n",
        "    y_test_pred_poly,\n",
        "    class_names,\n",
        "    correct=True,\n",
        "    n=6,\n",
        "    title=\"Poly SVM – Correct Predictions\"\n",
        ")\n",
        "\n",
        "show_examples(\n",
        "    x_test,\n",
        "    y_test_flat,\n",
        "    y_test_pred_poly,\n",
        "    class_names,\n",
        "    correct=False,\n",
        "    n=6,\n",
        "    title=\"Poly SVM – Incorrect Predictions\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZgasxpWcsGlL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}